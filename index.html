<head>
    <title>Yanze Wu</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="author" content="Yanze Wu">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta property="og:title" content="Yanze Wu">
    <!-- <meta property="og:image" content="files/image.jpg"> -->
    <!-- 	<meta name="twitter:card" content="summary_large_image"> -->
    <link rel="apple-touch-icon" href="files/uts-logo.png">
    <link rel="icon" type="image/png" href="files/uts-logo.png">
    <link rel="manifest" href="files/site.webmanifest">
    <link rel="stylesheet" href="style.css">
</head>

<div class="header noselect">
    <div class="content row">
        <!-- <div class="header-profile-picture"></div> -->
        <div class="header-text">
            <div class="header-name">
                <h1>Yanze Wu</h1>
            </div>
            <div class="header-subtitle">
                Researcher @ ByteDance
            </div>
            <div class="header-links">
                <a class="btn" href="https://github.com/ToTheBeginning">GitHub</a> /
                <a class="btn" href="https://scholar.google.com/citations?user=FdHiVvkAAAAJ&hl=zh-CN">Google Scholar</a>
                /
                <a class="btn" href="#contact">Email</a>
            </div>
        </div>
    </div>
</div>
<div class="content" style="padding-bottom: 64px;">
    <div>
        <p>
            I am currently a Senior Researcher at ByteDance Intelligent Creation (since August 2023), focusing on AIGC
            topics.
            Prior to joining ByteDance,
            I spent over three years at <a href="https://arc.tencent.com/en/index">Tencent ARC Lab</a>, where I worked
            closely with <a href="https://xinntao.github.io/">Dr. Xintao Wang</a> and <a
                href="https://yu-li.github.io/">Dr. Yu
                Li</a>. I obtained my master's degree from Fudan University in 2020.
        </p>
        <p>
            My research interests lie in <b>AIGC</b>, especially Image/Video Controllable Generation and Customized Generation.
        </p>
        <!-- <p>
            <font color="#FF8C00">We are looking for research interns at ByteDance Intelligent Creation (base Shanghai or Beijing) to
                work on video content
                creation topics. Feel
                free to contact me if you are interested! </font>
        </p> -->
    </div>

    <div>
        <h2 class="noselect">News</h2>
        <ul>
            <li>
                [05/2025] We release <a href="https://github.com/bytedance/DreamO">DreamO</a>, a unified framework for image customization.
            </li>
            <li>
                [09/2024] PuLID accepted by NeurIPS 2024. Check our <a href="https://github.com/ToTheBeginning/PuLID?tab=readme-ov-file#triangular_flag_on_post-updates">recent updates</a>, including <a href="https://huggingface.co/spaces/yanze/PuLID-FLUX">PuLID-FLUX</a>.
            </li>
            <li>
                [05/2024] We release <a href="https://github.com/ToTheBeginning/PuLID">PuLID</a>, a pure and lightning ID customization method.
            </li>
            <li>
                [04/2024] The extension of MM-RealSR was accepted by TPAMI.
            </li>
            <li>
                [02/2024] One paper was accepted by CVPR 2024 as <font color="#F4B95E">Highlight</font> (11.9%).
            </li>
            <li>
                [12/2023] One paper was accepted by AAAI 2024.
            </li>
            <li>
                [09/2022] One paper was accepted by NeurIPS 2022.
            </li>
            <li>
                [07/2022] One paper was accepted by ECCV 2022.
            </li>
            <li>
                [07/2021] One paper was accepted by ICCV 2021.
            </li>
        </ul>
    </div>

    <div>
        <h2 class="noselect">Publications</h2>
        <p>(* equal contribution, <sup>#</sup> corresponding author)</p>
        <div class="publication row clearfix">
            <div class="row-media" style="background-image: url(images/dreamo.jpeg);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="https://arxiv.org/abs/2504.16915">DreamO: A Unified Framework for Image Customization</a><br />
                by ByteDance Intelligent Creation (Core Contributor & Corresponding Author)<br />
                <span class="italic"><a href="https://asia.siggraph.org/2025">SIGGRAPH Asia</a></span>, 2025<br />
                <a class="btn btn-red" href="https://arxiv.org/abs/2504.16915">Paper (arXiv)</a>
                / <a class="btn" href="https://github.com/bytedance/DreamO">Codes (GitHub)</a>
                / <a class="btn" href="https://huggingface.co/spaces/ByteDance/DreamO">ðŸ¤— Demo</a>
                <img src="https://img.shields.io/github/stars/bytedance/DreamO?style=flat&amp;label=Stars&amp;logo=github&amp;labelColor=f6f6f6&amp;color=9cf&amp;logoColor=020d12" align="right" />
            </div>
        </div>
        <div class="publication row clearfix">
            <div class="row-media" style="background-image: url(images/pulid.jpg);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="https://arxiv.org/abs/2404.16022">PuLID: Pure and Lightning ID Customization via Contrastive Alignment</a><br />
                Zinan Guo*, <span class="bold">Yanze Wu*<sup>#</sup></span>, Zhuowei Chen, Lang Chen, Peng Zhang, Qian He<br />
                <span class="italic"><a href="https://nips.cc/Conferences/2024">NeurIPS</a></span>, 2024<br />
                <a class="btn btn-red" href="https://arxiv.org/abs/2404.16022">Paper (arXiv)</a>
                / <a class="btn" href="https://github.com/ToTheBeginning/PuLID">Codes (GitHub)</a>
                / <a class="btn" href="https://huggingface.co/spaces/yanze/PuLID">PuLID ðŸ¤— demo</a>
                / <a class="btn" href="https://huggingface.co/spaces/yanze/PuLID-FLUX">PuLID-FLUX ðŸ¤— demo</a>
                <img src="https://img.shields.io/github/stars/ToTheBeginning/PuLID?style=flat&amp;label=Stars&amp;logo=github&amp;labelColor=f6f6f6&amp;color=9cf&amp;logoColor=020d12" align="right" />
            </div>
        </div>
        <div class="publication row clearfix">
            <div class="row-media" style="background-image: url(images/deadiff.jpg);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="https://arxiv.org/abs/2403.06951">DEADiff: An Efficient
                    Stylization Diffusion Model with Disentangled Representations</a><br />
                Tianhao Qi, Shancheng Fang, <span class="bold">Yanze Wu</span>, Hongtao Xie, Jiawei Liu, Lang Chen, Qian
                He, Yongdong Zhang<br />
                <span class="italic"><a href="https://cvpr.thecvf.com/Conferences/2024">CVPR</a></span>, 2024, Selected
                as Highlight (11.9%)<br />
                <a class="btn btn-red" href="https://arxiv.org/abs/2403.06951">Paper (arXiv)</a>
                / <a class="btn" href="https://tianhao-qi.github.io/DEADiff/">Project Page</a>
                / <a class="btn" href="https://github.com/bytedance/DEADiff">Codes (GitHub)</a>
                <img src="https://img.shields.io/github/stars/bytedance/DEADiff?style=flat&amp;label=Stars&amp;logo=github&amp;labelColor=f6f6f6&amp;color=9cf&amp;logoColor=020d12" align="right" />

            </div>
        </div>
        <div class="publication row clearfix">
            <div class="row-media" style="background-image: url(images/t2i-adapter-car.png);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="https://arxiv.org/abs/2302.08453">T2I-Adapter: Learning Adapters
                    to Dig out More Controllable Ability for Text-to-Image Diffusion Models</a><br />
                Chong Mou, Xintao Wang, Liangbin Xie, <span class="bold">Yanze Wu</span>, Jian Zhang, Zhongang Qi, Ying
                Shan, Xiaohu Qie<br />
                <span class="italic">Annual AAAI Conference on Artificial Intelligence (<a
                        href="https://aaai.org/aaai-conference/">AAAI</a>)</span>, 2024<br />
                <a class="btn btn-red" href="https://arxiv.org/abs/2302.08453">Paper (arXiv)</a>
                / <a class="btn" href="https://github.com/TencentARC/T2I-Adapter">Codes (GitHub)</a>
                <img src="https://img.shields.io/github/stars/TencentARC/T2I-Adapter?style=flat&amp;label=Stars&amp;logo=github&amp;labelColor=f6f6f6&amp;color=9cf&amp;logoColor=020d12" align="right" />
            </div>
        </div>
        <div class="publication row clearfix">
            <div class="row-media" style="background-image: url(images/animesr.jpg);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="https://arxiv.org/abs/2206.07038">AnimeSR: Learning Real-World
                    Super-Resolution Models for Animation Videos</a><br />
                <span class="bold">Yanze Wu*</span>, Xintao Wang*, Gen Li, Ying Shan<br />
                <span class="italic">Advances in Neural Information Processing Systems (<a
                        href="https://nips.cc/Conferences/2022">NeurIPS</a>)</span>, 2022<br />
                <a class="btn btn-red" href="https://arxiv.org/abs/2206.07038">Paper (arXiv)</a>
                / <a class="btn" href="https://github.com/TencentARC/AnimeSR">Codes (GitHub)</a>
                <img src="https://img.shields.io/github/stars/TencentARC/AnimeSR?style=flat&amp;label=Stars&amp;logo=github&amp;labelColor=f6f6f6&amp;color=9cf&amp;logoColor=020d12" align="right" />
            </div>
        </div>
        <div class="publication row clearfix">
            <div class="row-media" style="background-image: url(images/MM-RealSR.png);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="https://arxiv.org/abs/2205.05065">MM-RealSR: Metric Learning
                    based Interactive Modulation for Real-World Super-Resolution</a><br />
                Chong Mou, <span class="bold">Yanze Wu</span>, Xintao Wang, Chao Dong, Jian Zhang, Ying Shan<br />
                <span class="italic">European Conference on Computer Vision (<a
                        href="https://eccv2022.ecva.net/">ECCV</a>)</span>, 2022 <br />
                <a class="btn btn-red" href="https://arxiv.org/abs/2205.05065">Paper (arXiv)</a>
                / <a class="btn" href="https://github.com/TencentARC/MM-RealSR">Codes (GitHub)</a>
                <img src="https://img.shields.io/github/stars/TencentARC/MM-RealSR?style=flat&amp;label=Stars&amp;logo=github&amp;labelColor=f6f6f6&amp;color=9cf&amp;logoColor=020d12" align="right" />
            </div>
        </div>
        <div class="publication row clearfix">
            <div class="row-media" style="background-image: url(images/colorization.png);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="https://arxiv.org/abs/2108.08826">Towards
                    Vivid and Diverse Image Colorization with Generative Color Prior</a><br />
                <span class="bold">Yanze Wu</span>, Xintao Wang, Yu Li, Honglun Zhang, Xun Zhao, Ying Shan<br />
                <span class="italic">IEEE International Conference on Computer Vision (<a
                        href="https://iccv2021.thecvf.com/home/">ICCV</a>)</span>, 2021 <br />
                <a class="btn btn-red" href="https://arxiv.org/abs/2108.08826">Paper (arXiv)</a>
                / <a class="btn" href="https://github.com/ToTheBeginning/GCP-Colorization">Codes (GitHub)</a>
                <img src="https://img.shields.io/github/stars/ToTheBeginning/GCP-Colorization?style=flat&amp;label=Stars&amp;logo=github&amp;labelColor=f6f6f6&amp;color=9cf&amp;logoColor=020d12" align="right" />
            </div>
        </div>
    </div>

    <div>
        <a id="honor"></a>
        <h2>Awards</h2>
        <p>
            Silver Medal of The 2015 ACM/ICPC Asia EC-Final Contest, 2015<br>
            Silver Medal of The 2015 ACM/ICPC Asia Changchun Regional Contest, 2015<br>
            Silver Medal of The 2016 ACM/ICPC Asia Qingdao Regional Contest, 2016<br>
        </p>
    </div>

    <div>
        <a id="service"></a>
        <h2>Academic Services</h2>
        <p>
            Conference Reviewer: CVPR, ICCV, ECCV, NeurIPS
        </p>
    </div>

    <div class="noselect">
        <a id="contact"></a>
        <h2>Contact</h2>
        I can be contacted directly at <span class="bold">wuyanze123</span> [at] <span class="bold">gmail</span>.com. I
        typically respond within a few days.
    </div>
</div>
<div class="footer noselect">
    <div class="footer-content">
        Thanks for the website design from Nicklas Hansen <a href="https://nicklashansen.github.io/">here</a>.
    </div>
</div>